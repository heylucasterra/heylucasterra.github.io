---
path: '/projects/bias'
title: 'Bias in → Bias out'
company: 'Mesa & Cadeira'
accent: 'var(--bg-lightest)'
location: São Paulo, Brazil
date: '2018'
subtitle: 'Raising awareness to the issues generated by our own biases when building software'
designteam: Rogier Klomp and many others
topics: product design
published: false
featuredImage: './posts/nubank/images/shell.png'
impact: big
role: "Co-authored the script for the 'machine', visuals and the set up for the venture"
color: 'black'
---

### Context
In 2018 I joined a group of data analysts, programmers, anthropologists, film makers, artists and journalists to raise awareness of our duty to the public good. The result was a series of videos on how our biases are embedded in the lines of code that shape our lives.

### The videos
In each video we invited people to go into a conversation with an algorithm. Their goal, was to train an unbiased algorithm on 5 different topics.

Would you be able to program an unbiased machine?


#### Hiring
`video: ./images/bias/bias-hiring.mp4`

#### Love
`video: ./images/bias/bias-love.mp4`

#### Gender
`video: ./images/bias/bias-gender.mp4`

#### Emoji
`video: ./images/bias/bias-emoji.mp4`

#### Lying
`video: ./images/bias/bias-lying.mp4`


On the 6th day working together we held an exhibition in the cultural heart of São Paulo, inviting the press and general public to watch our creations and ignite the discussion on the topic.

`video: ./images/bias/bias-making-of.mp4`

